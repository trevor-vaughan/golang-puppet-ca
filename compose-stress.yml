# Upper-limit stress test topology for puppet-ca.
#
# Purpose: find the saturation ceiling — NOT a pass/fail test.
# k6 ramps arrival rate until the server can no longer keep up,
# then reports where latency and dropped_iterations spike.
#
# WARNING: This will deliberately push puppet-ca to (and past) its limits.
#          Do not run against a shared or production server.
#
# Usage:
#   mage stress                                          # run and tear down
#   podman-compose -f compose-stress.yml up --build     # interactive

name: puppet-ca-stress

services:

  # ── CA server ─────────────────────────────────────────────────────────────
  puppet-ca:
    build:
      context: .
      dockerfile: Dockerfile.run
    image: puppet-ca-integ:latest
    command:
      - --cadir=/data
      - --autosign-config=true   # write scenario uses /generate (no CSR needed)
      - --no-tls-required        # test-only stack; CA not reachable from outside compose network
      - -v=0                     # INFO level: per-cert ops are DEBUG; only WARN/ERROR visible under load
    expose:
      - "8140"
    volumes:
      - ca-data:/data
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8140/healthz/ready"]
      interval: 3s
      timeout: 5s
      retries: 20
      start_period: 8s

  # ── k6 stress runner ──────────────────────────────────────────────────────
  k6:
    image: grafana/k6:latest
    tty: true       # allocate a PTY so k6 uses its live updating progress display
    command:
      - run
      - --env
      - CA_URL=http://puppet-ca:8140
      - /test/stress.js
    environment:
      # Passed in by `mage test:stress` via systemInfo(); used in the final report.
      - REPORT_HOST
      - REPORT_CPUS
      - REPORT_MEM_GB
      - REPORT_KERNEL
    volumes:
      - ./test:/test:ro,z
    depends_on:
      puppet-ca:
        condition: service_healthy

volumes:
  ca-data:
